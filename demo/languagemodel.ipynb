{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hwr.lm.generate_lm import update_counter\n",
    "from hwr.lm.lm import KneserNeyBackoff\n",
    "from nltk.lm import NgramCounter, Vocabulary\n",
    "from nltk.util import everygrams\n",
    "from hwr.constants import ON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small demo for the character level language model, which is used in the decoding of RNN output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d',), ('o',), ('g',), ('d', 'o'), ('o', 'g'), ('d', 'o', 'g')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3 gram KN smoothed stupid back off model\n",
    "# with only the word 'dog'\n",
    "counter = NgramCounter()\n",
    "test_text = 'dog'\n",
    "everygram = list(everygrams(test_text, max_len=3))\n",
    "counter = NgramCounter()\n",
    "counter.update([everygram])\n",
    "lm = KneserNeyBackoff(3, backoff=0.5, counter=counter, vocabulary=Vocabulary(ON.DATA.CHARS))\n",
    "everygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012048192771084338,\n",
       " 0.012048192771084338,\n",
       " 0.012048192771084338,\n",
       " 0.012048192771084338)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unigram scores are same for KN smoothing\n",
    "lm.score('g'), lm.score('d'), lm.score('o'), lm.score('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9901204819277108, 0.9012048192771085)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(g|do), P(g|o)\n",
    "p_g_do = lm.score('g', ['d','o'])\n",
    "p_g_o = lm.score('g', ['o'])\n",
    "p_g_do, p_g_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45060240963855425, 0.0030120481927710845)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"no occurance of \"fog\", so by stupid backoff\n",
    "# P(g|fo) = 0.5 * P(g|o)\n",
    "# both \"bag\" and \"ag\" has no occurence,\n",
    "# P(g|ba) = 0.5 ^ 2 * P(g)\n",
    "p_g_fo = lm.score('g', ['f','o'])\n",
    "p_g_ba = lm.score('g', ['b','a'])\n",
    "p_g_fo, p_g_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating counter with file:\n",
      "../../data/1blm/lm_example.txt\n",
      "Updating ngrams:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00,  7.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# update counter to 9 gram with the example text\n",
    "counter = NgramCounter()\n",
    "update_counter(counter, 9, '../../data/1blm/lm_example.txt')\n",
    "lm = KneserNeyBackoff(9, backoff=0.4, counter=counter, vocabulary=Vocabulary(ON.DATA.CHARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7029019364108138, 0.00026147141758523456)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(e|th) and P(k|th)\n",
    "lm.score('e', list('th')), lm.score('k', list('th'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
